{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to download all modules first using 'conda/pip install {module_name}' in Anaconda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import nltk\n",
    "import pytz\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_df(path):\n",
    "    \"\"\"\n",
    "    Load and combine all JSON files in the inbox folder into one Pandas dataframe.\n",
    "    Assumes that all JSON files in the inbox folder have similar formats.\n",
    "    \n",
    "    Parameters\n",
    "    ---------------\n",
    "    path (str): Path of inbox folder containing Facebook messages\n",
    "    \n",
    "    Output\n",
    "    ---------------\n",
    "    Pandas dataframe \n",
    "    \"\"\"\n",
    "    ## Initialize empty lists and tables\n",
    "    folder_lst = []\n",
    "    json_lst = []\n",
    "    message_tbl = pd.DataFrame()\n",
    "    \n",
    "    ## Get all JSON files in each folder\n",
    "    for folder in os.listdir(path):\n",
    "        for file in os.listdir(f'{path}/{folder}'):\n",
    "            if file.endswith('.json'):\n",
    "                json_lst += [f'{path}/{folder}/{file}']\n",
    "            \n",
    "    ## Populate table\n",
    "    for json_file in json_lst:\n",
    "        thread = re.search('//(.+?)_', json_file).group(1)\n",
    "        with open(json_file) as json_data:\n",
    "             data = json.load(json_data)\n",
    "        tmp_df = pd.DataFrame(data['messages'])\n",
    "        tmp_df['thread'] = thread\n",
    "        message_tbl = message_tbl.append(tmp_df, ignore_index = True)\n",
    "        \n",
    "    ## Convert timestamp to datetime\n",
    "    message_tbl['date'] = pd.to_datetime(message_tbl['timestamp_ms'], unit = 'ms', utc = True)\n",
    "    message_tbl['date'] = message_tbl['date'].dt.tz_convert('Asia/Singapore')\n",
    "    message_tbl['year'] = message_tbl['date'].dt.year\n",
    "    message_tbl = message_tbl[message_tbl['year'] == 2021] ## Only get 2021 messages. Remove if desired.\n",
    "    message_tbl['hour'] = message_tbl['date'].dt.hour \n",
    "    message_tbl['date'] = message_tbl['date'].dt.date ## Get date only (from datetime)\n",
    "    message_tbl = message_tbl[['thread','sender_name','content','date','hour']]\n",
    "            \n",
    "    return message_tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def messages_to_words(df, stopword_lst, min_freq):\n",
    "    \"\"\"\n",
    "    Cleans and splits Facebook messages into individual words.\n",
    "    \n",
    "    Parameters\n",
    "    ---------------\n",
    "    df (Pandas dataframe) : Dataframe of all messages (output of json_to_df)\n",
    "    stopword_lst (list)   : List of all stopwords (words to remove)\n",
    "    min_freq (int)        : Minimum frequency of words to include in analysis\n",
    "    \n",
    "    Output\n",
    "    ---------------\n",
    "    Pandas dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    ## Convert messages to lowercase\n",
    "    df['content'] = df['content'].astype(str).str.lower() \n",
    "\n",
    "    ## Remove all punctuations\n",
    "    df['content'] = df['content'].str.replace(r'[^\\w\\s]+', '')\n",
    "\n",
    "    ## Tokenize messages (into words)\n",
    "    df['content_token'] = df['content'].apply(word_tokenize) \n",
    "\n",
    "    ## Remove stopwords\n",
    "    df['content_token'] = df['content_token'].apply(lambda x: [item for item in x if item not in stopword_lst])\n",
    "    \n",
    "    ## Split phrases into separate words, and remove infrequent words\n",
    "    df = df.explode('content_token')\n",
    "\n",
    "    count_tbl = pd.DataFrame(df['content_token'].value_counts())\n",
    "    count_tbl.reset_index(inplace = True)\n",
    "    count_tbl.columns = ['content_token', 'freq']\n",
    "\n",
    "    df = df.merge(count_tbl, on = 'content_token')\n",
    "    df = df[df['freq'] >= min_freq] \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-4d1a50edf404>:20: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['content'] = df['content'].str.replace(r'[^\\w\\s]+', '')\n"
     ]
    }
   ],
   "source": [
    "inbox_dir = 'messages/inbox/' ## Change to file directory of Messenger inbox\n",
    "\n",
    "#################################\n",
    "## Compile all messages \n",
    "#################################\n",
    "message_tbl = json_to_df(inbox_dir)\n",
    "\n",
    "#################################\n",
    "## Add stopwords\n",
    "#################################\n",
    "filipino_stopwords = pd.read_csv('stopwords_tl.csv')\n",
    "filipino_stopwords = filipino_stopwords['word'].to_list()\n",
    "all_stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "## Append Filipino stopwords\n",
    "all_stopwords.extend(filipino_stopwords) \n",
    "\n",
    "## Add other stopwords\n",
    "other_stopwords = ['okay', 'sige', 'ung', 'din', 'rin', 'nan',\n",
    "                  'haha', 'hahaha', 'hahahaha', 'hahahahaha', 'hahahahahaha', 'oh', 'u', '1', '2', '3',\n",
    "                  'poll','reacted', 'รฐ', 'ok', 'po'] ## Add stopwords as desired\n",
    "all_stopwords.extend(other_stopwords)\n",
    "\n",
    "#################################\n",
    "## Data transformation\n",
    "#################################\n",
    "message_tbl = messages_to_words(message_tbl, all_stopwords, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Change to your Facebook name\n",
    "my_name = 'test' \n",
    "\n",
    "## Indicate whether message was sent or received\n",
    "message_tbl['message_status'] = np.where(message_tbl['sender_name'] == my_name, 'Sent', 'Received') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of messages sent and received (Overall, per day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "## Count messages per date\n",
    "#################################\n",
    "date_tbl = pd.DataFrame(message_tbl.drop_duplicates(['content']).groupby('message_status')['date'].value_counts())\n",
    "date_tbl = date_tbl.rename(columns = {'date':'count'}).reset_index()\n",
    "date_tbl = date_tbl.sort_values(['date'])\n",
    "\n",
    "#################################\n",
    "## Data visualization\n",
    "#################################\n",
    "sns.set(font_scale = 1.2) \n",
    "sns.set_style(\"whitegrid\")\n",
    "plot = sns.FacetGrid(date_tbl, row = 'message_status', hue = 'message_status', height = 5, aspect = 3)\n",
    "plot.map(plt.plot, 'date', 'count') \n",
    "plot.map(plt.fill_between, 'date', 'count', alpha= 0.4)\n",
    "plot.set(xlabel = 'Date', ylabel = 'Number of messages')\n",
    "plot.fig.subplots_adjust(top=0.89)\n",
    "plt.subplots_adjust(hspace = 0.2)\n",
    "plot.fig.suptitle('Number of messages sent and received in 2021')\n",
    "\n",
    "date_format = mdates.DateFormatter(\"%m/%d/%y\")\n",
    "plot.axes[0,0].xaxis.set_major_formatter(date_format)\n",
    "plot.axes[0,0].xaxis.grid(False)\n",
    "plot.axes[1,0].xaxis.grid(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of messages sent and received (Overall, per hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "## Count messages per hour\n",
    "#################################\n",
    "hour_tbl = pd.DataFrame(message_tbl.drop_duplicates(['content']).groupby('message_status')['hour'].value_counts())\n",
    "hour_tbl = hour_tbl.rename(columns = {'hour':'count'}).reset_index()\n",
    "hour_tbl = hour_tbl.sort_values(['hour'])\n",
    "hour_tbl = hour_tbl.pivot(index = 'hour', columns = 'message_status', values = 'count')\n",
    "\n",
    "#################################\n",
    "## Data visualization\n",
    "#################################\n",
    "\n",
    "sns.set(font_scale = 1.2, \n",
    "        rc={'figure.figsize':(11,8)})\n",
    "sns.set_style(\"whitegrid\")\n",
    "plot = hour_tbl.plot(kind = 'bar', stacked = 'True')\n",
    "plot.xaxis.grid(False)\n",
    "plot.set(xlabel = 'Hour', ylabel = 'Messages received', \n",
    "         title = 'Number of messages received and sent per hour')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top n words (Overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "\n",
    "#################################\n",
    "## Get top words\n",
    "#################################\n",
    "word_tbl = pd.DataFrame(message_tbl.groupby('message_status')['content_token'].value_counts())\n",
    "top_n_words = word_tbl.rename(columns = {'content_token':'count'}).reset_index().groupby('message_status').head(n)\n",
    "\n",
    "#################################\n",
    "## Data visualization\n",
    "#################################\n",
    "sns.set(font_scale = 1.2) \n",
    "sns.set_style(\"whitegrid\")\n",
    "plot = sns.FacetGrid(top_n_words, col = 'message_status', hue = 'message_status', sharex = False, height = 5, aspect = 1.5)\n",
    "plot.map_dataframe(sns.barplot, x = 'content_token', y = 'count') \n",
    "plot.fig.subplots_adjust(top=0.85)\n",
    "plot.fig.suptitle(f'Top {n} words used in messages')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top n people most talked to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "\n",
    "################################\n",
    "## Get top people\n",
    "#################################\n",
    "user_tbl = pd.DataFrame(message_tbl[message_tbl['sender_name'] != my_name].drop_duplicates(['content']).value_counts('sender_name'))\n",
    "user_tbl = user_tbl.rename(columns = {0:'count'}).reset_index().head(n)\n",
    "\n",
    "################################\n",
    "## Data visualization\n",
    "#################################\n",
    "\n",
    "sns.set(font_scale = 1.2, rc={'figure.figsize':(12,9)}) \n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.color_palette(\"husl\", 8)\n",
    "plot = sns.barplot(x = 'count', y = 'sender_name', data = user_tbl)\n",
    "plot.set(xlabel = 'Number of messages received', ylabel = 'Sender name',\n",
    "        title = f'Top {n} people talked to in 2021')\n",
    "plot.bar_label(plot.containers[0], padding = 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of messages received (Specific users, per day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_lst = ['adriancortes'] ## Names of threads to include\n",
    "\n",
    "#################################\n",
    "## Count messages per date\n",
    "#################################\n",
    "date_tbl_per_thread = message_tbl[message_tbl['thread'].isin(thread_lst)]\n",
    "date_tbl_per_thread = pd.DataFrame(date_tbl_per_thread.drop_duplicates(['content']).groupby('sender_name')['date'].value_counts())\n",
    "date_tbl_per_thread = date_tbl_per_thread.rename(columns = {'date':'count'}).reset_index().sort_values(['date'])\n",
    "\n",
    "#################################\n",
    "## Data visualization\n",
    "#################################\n",
    "sns.set(font_scale = 1.2, \n",
    "        rc={'figure.figsize':(11,8)})\n",
    "sns.set_style(\"whitegrid\")\n",
    "plot = sns.FacetGrid(date_tbl_per_thread, row = 'sender_name', hue = 'sender_name', height = 5, aspect = 3)\n",
    "plot = plot.map(plt.plot, 'date', 'count') \n",
    "plot = plot.map(plt.fill_between, 'date', 'count', alpha= 0.4)\n",
    "\n",
    "date_format = mdates.DateFormatter(\"%m/%d/%y\")\n",
    "plot.axes[0,0].xaxis.set_major_formatter(date_format)\n",
    "plot.axes[0,0].xaxis.grid(False)\n",
    "plot.axes[1,0].xaxis.grid(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of messages received (Specific users, per hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_lst = [''] ## Names of threads to include\n",
    "\n",
    "#################################\n",
    "## Count messages per date\n",
    "#################################\n",
    "hour_tbl_per_thread = message_tbl[message_tbl['thread'].isin(thread_lst)]\n",
    "hour_tbl_per_thread = pd.DataFrame(hour_tbl_per_thread.drop_duplicates(['content']).groupby('sender_name')['hour'].value_counts())\n",
    "hour_tbl_per_thread = hour_tbl_per_thread.rename(columns = {'hour':'count'}).reset_index().sort_values(['hour'])\n",
    "hour_tbl_per_thread = hour_tbl_per_thread.pivot(index = 'hour', columns = 'sender_name', values = 'count')\n",
    "\n",
    "#################################\n",
    "## Data visualization\n",
    "#################################\n",
    "sns.set(font_scale = 1.2, \n",
    "        rc={'figure.figsize':(11,8)})\n",
    "sns.set_style(\"whitegrid\")\n",
    "plot = hour_tbl_per_thread.plot(kind = 'bar', stacked = 'True')\n",
    "plot.xaxis.grid(False)\n",
    "plot.set(xlabel = 'Hour', ylabel = 'Messages received', \n",
    "         title = 'Number of messages sent per hour by users')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top n words (Specific users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_lst = [''] ## Check thread name in message_tbl\n",
    "n = 10 \n",
    "\n",
    "#################################\n",
    "## Get top words\n",
    "#################################\n",
    "thread_tbl = pd.DataFrame(message_tbl[message_tbl['thread'].isin(thread_lst)].groupby('sender_name')['content_token'].value_counts())\n",
    "top_n_words_per_thread = thread_tbl.groupby('sender_name').head(n)\n",
    "top_n_words_per_thread = top_n_words_per_thread.rename(columns = {'content_token':'count'}).reset_index()\n",
    "\n",
    "#################################\n",
    "## Data visualization\n",
    "#################################\n",
    "sns.set(font_scale = 1.2) \n",
    "sns.set_style(\"whitegrid\")\n",
    "plot = sns.FacetGrid(top_n_words_per_thread, row = 'sender_name', hue = 'sender_name', sharex = False, height = 5, aspect = 1.5)\n",
    "plot.map_dataframe(sns.barplot, x = 'content_token', y = 'count') \n",
    "plot.fig.subplots_adjust(top=0.93)\n",
    "plot = plot.fig.suptitle(f'Top {n} words used by each user')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
